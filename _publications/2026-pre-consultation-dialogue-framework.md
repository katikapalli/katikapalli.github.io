---
layout: publication
title: "PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis"
authors:
  - name: "K Lokesh"
    superscript: "1"
    # link: "{{ site.homepage }}"
  - name: "Abhirama Subramanyam Penamakuri"
    superscript: "1"
    # link: "https://abhiram4572.github.io/"
  - name: "Uday Agarwal"
    superscript: "1"
    link: ""
  - name: "Apoorva Challa"
    superscript: "2"
    link: ""
  - name: "Shreya K Gowda"
    superscript: "2"
    link: ""
  - name: "Somesh Gupta"
    superscript: "2"
    link: ""
  - name: "Anand Mishra"
    superscript: "1"
    # link: "https://anandmishra22.github.io/"
  
affiliations:
  - "Indian Institute of Technology Jodhpur"
  - "All India Institute of Medical Sciences Delhi"
links:
  Page: "https://vl2g.github.io/projects/pcdf"
  ArXiV: "https://arxiv.org/abs/2601.10945"
  Paper: "/assets/publications/2026-pre-consultation-dialogue-framework/paper.pdf"
  Code: "https://github.com/vl2g/pcdf"
  Checkpoint: "https://huggingface.co/vl2g/PCDF_Qwen_2.5-VL-7B-Instruct-DermaMNIST"
  
abstract: >
  Traditionally, AI research in medical diagnosis has largely centered on image analysis. While this has led to notable advancements, the absence of patient-reported symptoms continues to hinder diagnostic accuracy. To address this, we propose a Pre-Consultation Dialogue Framework (PCDF) that mimics real-world diagnostic procedures, where doctors iteratively query patients before reaching a conclusion. Specifically, we simulate diagnostic dialogues between two vision–language models (VLMs): a DocVLM, which generates follow-up questions based on the image and dialogue history, and a PatientVLM, which responds using a symptom profile derived from the ground-truth diagnosis. We additionally conducted a small-scale clinical validation of the synthetic symptoms generated by our framework, with licensed clinicians confirming their clinical relevance, symptom coverage, and overall realism. These findings indicate that the resulting DocVLM–PatientVLM interactions form coherent, multi-turn consultations paired with images and diagnoses, which we then use to fine-tune the DocVLM. This dialoguebased supervision leads to substantial gains over image-only training, highlighting the value of realistic symptom elicitation for diagnosis. 
bibtex: |
  @inproceedings{lokesh2026patientvlm,
  title     = {PatientVLM Meets DocVLM: Pre-Consultation Dialogue Between Vision-Language Models for Efficient Diagnosis},
  author    = {Lokesh, K and Penamakuri, Abhirama Subramanyam and Agarwal, Uday and Challa, Apoorva and Gowda, Shreya K and Gupta, Somesh and Mishra, Anand},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  year      = {2026},
  publisher = {AAAI Press}
  }
---